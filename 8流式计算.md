# 8-流式计算
## 批处理计算
* 批处理是大数据计算中一类常见的计算任务，主要操作大容量静态数据集，并在计算过程完成后返回结果
* 批处理模式中使用的数据集通常具有下列特征：
  * 有界——批处理数据集代表数据的有限集合；
  * 持久——数据通常始终存储在某种类型的持久存储位置中；
  * 大量——批处理操作通常是处理极为海量数据集的唯一方法

* 批处理需要访问全套记录才能完成的计算工作。例如计算总数，必须将数据集作为一个整体加以处理。处理需要付出大量时间，不适合对处理时间要求较高的场合

## 流式计算
* 流处理系统会对随时进入系统的数据进行计算，无需针对整个数据集执行操作
* 流式计算特点：
  * 流处理中的数据集是“无边界”的，数据集只能代表截至目前已经进入到系统中的数据总量。
  * 流处理系统可以处理几乎无限量的数据，但同一时间只能处理一条（真正的流处理）或很少量（微批处理，Microbatch Processing）数据。
  * 处理工作是基于事件的，除非明确停止否则没有“尽头”。处理结果立刻可用，并会随着新数据的抵达继续更新


* 有近实时处理需求的任务很适合使用流处理模式。
* 流式计算(Stream Processing)是越来越受到重视的一个计算领域。在很多应用场所，对大数据处理的计算时效性要求很高，要求计算能够在非常短的时延(Low Latency)内完成，这样能够更好地发挥流式计算系统的威力。

## 流式计算一般框架
* 流式计算一般框架可以分为三部分：
  * 数据实时采集
    * --Apache Flume：日志，事件等数据资源的收集系统
    * ---Kafka：一个可持久化的分布式的消息队列（自带存储）
  * 数据实时计算（流式计算系统）
    * ---Storm：Apache顶级项目，基于DAG计算模型
    * ---S4: Yahoo的分布式流计算平台，P2P结构
    * ---Samza：Apache开源项目，将流作为消息处理
    * ---Spark Streaming：Apache Spark子项目
  * 流式计算应用
    * ---Druid：大数据实时查询和分析系统
    * ---Splunk：机器数据（系统，集群等数据）分析引擎

## 流式计算系统
* 当前的流式计算系统可称为“可扩展数据流平台类”的计算系统。其设计初衷是出于模仿MapReduce计算框架的思路，即在对处理时效性有高要求的计算场景下，如何提供一个完善的计算框架，并暴露给用户少量的编程接口。使得用户能够集中精力处理应用逻辑。至于系统性能、低延迟、数据不丢失以及容错等问题，则由计算框架来负责。

## 流式计算系统的特点
* 相比批处理计算系统，流式计算系统具备特点：
  * 记录处理低延迟：从原始输入数据进入流式系统， 再流经各个计算节点后抵达系统输出端。整个计算过程所经历的时间越短越好，主流的流式计算系统对于记录的处理时间应该在毫秒级
  * 极佳的系统容错性：保证数据不会丢失、保证数据的送达，以及对计算状态的持久化、快速的计算迁移和故障恢复等都是必需的要求
  * 极强的系统扩展能力：在系统满足高可扩展的同时，不能因为系统规模增大而明显降低流式计算系统的处理速度。
  * 灵活强大的应用逻辑表达能力：应用逻辑描述的灵活性，操作原语的多样性与灵活性。

## 流式计算系统架构
* 主从模式：主控节点做全局管理比较简洁，比如Storm和Samza都是这类架构
* P2P模式：避免单点失效，但无中心控制节点，系统管理方面相对较复杂。如Yahoo的S4

## 流式计算系统：Storm
* Storm：一个开源框架，Apache顶级项目，来自Twitter公司，其目标是大数据流的实时处理。可以可靠地处理无限的数据流。
* 分布式
  * 水平扩展：通过加机器、提高并发数就提高处理能力
  * 自动容错：自动处理进程、机器、网络异常
* 实时：数据不写磁盘，延迟低（毫秒级）
* 流式：不断有数据流入、处理、流出
* 开源：twitter开源，社区很活跃

## Storm计算模型——DAG
<img width="767" alt="80c8e608cff13f4699ea322d94e21b8" src="https://github.com/user-attachments/assets/01fd1f71-3791-49e2-86bc-bc46431caa14">


## Storm计算模型——Stream
* Storm对于流Stream的抽象：流是一个不间断的无界的连续Tuple（元组，是元素有序列表）。
* Stream消息流，是一个没有边界的Tuple序列，这些Tuples会被以一种分布式的方式并行地创建和处理。

## Storm计算模型——Spout
* Storm认为每个Stream都有一个源头，该源头被抽象为Spouts
* Spout：流数据源，它会从外部读取流数据，并发出Tuple。也可以看出是从外部获取数据，同时输出原始的Tuple

## Storm计算模型——Bolt
* Storm将流的中间状态转换抽象为Bolts，Bolts可以处理Tuples，同时它也可以发送新的流给其他Bolts使用。
* Bolts：消息处理者，所有的消息处理逻辑被封装在Bolts里面，处理输入的数据流并产生输出的新数据流，可执行过滤，聚合，查询数据库等操作
* 接收 Spout/Bolt 输出的Tuple，处理，输出新Tuple。

## Storm计算模型——Task，Stream Groupings
<img width="764" alt="24ffce87f6b974f857b291402b46742" src="https://github.com/user-attachments/assets/fc9595cf-8b1f-4408-a5e1-afca83c8c304">

## Storm计算模型——Topology
<img width="771" alt="e1bc68ecc967569665ef7377d2f56db" src="https://github.com/user-attachments/assets/91a29fd0-4a9c-4776-a384-c96132ba5ae2">

## Storm体系架构——主从式
* 系统存在两类节点:主控节点和工作节点

<img width="752" alt="dd0261fe4eeb17a9755ac87f8a1a4c6" src="https://github.com/user-attachments/assets/c0b31691-85a9-452f-bec1-65b6854b6c05">

## Storm体系架构设计特点：
* Nimbus后台程序和Supervisor后台程序都是快速失败（fail-fast）和无状态的，所有状态维持在Zookeeper或本地磁盘。
* 这种设计中Nimbus并没有直接和Supervisor通信， 而是借助中介Zookeeper ， 这样可以分离Nimbus和Supervisor的依赖，将状态信息存放在zookeeper集群内以快速回复任何失败的一方。
* 这意味着你可以杀掉Nimbus进程和Supervisor进程，然后重启，它们将恢复状态并继续工作，这种设计使Storm极其稳定

## Storm系统执行单元：
* Worker：工作进程；拓扑以一个或多个Worker进程的方式运行。每个Worker进程是一个物理的Java虚拟机，执行拓扑的一部分任务。在Storm集群中，Worker是由Supervisor来生成，一台主机对应一个Supervisor，可生成一个或多个Worker。
* Executor：执行线程；1个worker进程会启动1个或多个executor线程来执行task。1个executor线程对应topology中一个组件（spout或bolt）的task。

<img width="542" alt="f9ae78c84e51bd98fe2fd4fb8fb9ebe" src="https://github.com/user-attachments/assets/f36e5401-1511-42a3-8bd0-8bf8828c8256">

## Storm工作流程/代码片段解析：
<img width="719" alt="d7b620c18578f3d7c4fb44bf60bb7a7" src="https://github.com/user-attachments/assets/fd7c9100-8e57-4e1e-82e3-d721c83cbf03">

<img width="776" alt="2168f29757d611b403747ccb1f3be0b" src="https://github.com/user-attachments/assets/f1761444-cee1-4f05-b0d6-7646f1b15518">


## 流式计算系统：Spark Streaming
* BDAS中的重要构成部分
* Spark Streaming是Spark核心API的一个扩展，可以实现高吞吐量的、具备容错机制的实时流数据的处理。
* Spark Streaming支持从多种数据源获取数据，包括Kafka、Flume、Twitter、ZeroMQ、Kinesis 以及TCP sockets
* 从数据源获取数据之后，可以使用诸如map、reduce、join等高级函数进行复杂算法的处理
* 最后还可以将处理结果存储到文件系统，数据库

* Spark Streaming工作机制：
  * Spark Streaming是将流式计算分解成一系列短小的批处理作业（mini-batch）。这里的批处理引擎是Spark Core。也就是把输入数据按照batch size分成一段一段的数据（Discretized Stream），每一段数据都会转换成Spark中的RDD
  * 然后将Spark Streaming中对DStream的Transformation操作变为针对Spark中对RDD的Transformation操作，将RDD经过操作变成中间结果保存在内存中。
  * 整个流式计算根据业务的需求可以对中间的结果进行叠加或者存储到外部设备。
  * 这是一个典型的生产者消费者模型。需要考虑如何协调生产速率和消费速率

* Spark Streaming架构：

<img width="624" alt="ce29850ab904ebcbb29b652fec3a4be" src="https://github.com/user-attachments/assets/86866a58-bfb4-4b25-8722-881d3ad1ea09">

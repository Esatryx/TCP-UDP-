# 4-数据采集2
## Apache Flume(日志数据采集)
* Flume是分布式、可靠、和高可用的海量日志采集、聚合和传输的日志收集系统。由Cloudera公司开源，连接数据源和数据存储系统的管道，屏蔽数据源和数据存储系统异构性的中间件
* Flume-OG基本架构

<img width="715" alt="b8a2c5565c3f1bbf53f99c8ea11e045" src="https://github.com/user-attachments/assets/67adb078-fe63-4662-a501-c698cc271a5a">

* 基于Flume-OG的美团日志收集系统

<img width="757" alt="4f0a216f5bfe8db62b431fa7554793d" src="https://github.com/user-attachments/assets/ebc0624e-d3ba-4c23-bcd0-486dea13acde">


* Flume-NG基本架构

<img width="774" alt="e0a6b5a0c619a15b8f098ff515b4695" src="https://github.com/user-attachments/assets/a50a5431-6f57-4173-8017-4a4a93722028">

* Flume-NG核心概念
  * Event：Flume数据传输的基本单元，由可选的header和载有数据的byte array构成， byte array可以携带日志数据。
  * Client：将原始日志文件包装成Events并发送它们到一个或多个Agent实体，由独立的线程运行
  * Agent：Flume的运行实体，包含Source, Channel, Sink等组件。利用这些组件将Events从一个节点传输到另一个节点或最终目的地。每台机器运行一个Agent
    * Source：负责接收Event或通过特殊机制产生Event，并将Events批量的放到一个或多个Channel
    * Channel：连接Source和Sink，类似event的缓存队列
    * Sink：接收Event，进行下一步转发

* Flume-OG V.S Flume-NG
  * Flume-OG有三种角色的节点， Flume-NG只有一种角色节点，降低臃肿性，更加灵活
  * 在OG版本中，Flume 的使用稳定性依赖 zookeeper；而在NG版本中，不再需要zookeeper对各类节点进行协调
  * 在Flume-NG中，agent节点的组成也发生了变化，由 source、sink、channel组成

* Flume拓扑结构

<img width="769" alt="a135a6a3718de50c9fc07bba20a2801" src="https://github.com/user-attachments/assets/df5b91ef-9394-477b-93e9-39f10d42dce8">

<img width="782" alt="ca5b9efba1d373ceaa82a77a3215af1" src="https://github.com/user-attachments/assets/c9874cc9-95d4-40dc-a032-428750bf57f9">

<img width="785" alt="3fddca163984cf73933332923560d3e" src="https://github.com/user-attachments/assets/2cf7e3d3-558c-4d41-9699-da0e236cd2d4">

<img width="776" alt="9fe87524407ec188a465bcaf0fa3c0e" src="https://github.com/user-attachments/assets/c4a2b7bd-b700-4514-b310-46a6e992a388">


## Apache Kafka(数据分发中间件)
* 为什么需要数据分发？
  * 前端数据采集后，需要送到后端进行分析处理。前端采集与后端处理往往是多对多的关系。之间需要数据分发中间件负责消息转发，保障消息可靠性，匹配前后端速度差
  * 分布式系统构件之间通过数据分发可以解除相互之间的功能耦合，从而减轻子系统之间的依赖，使得各个子系统或构件可以独立演进、维护或者重用

* 数据分发解决方案——消息队列
  * 消息队列是在消息传输过程中保存消息的容器或中间件，主要目的是提供消息路由并保障消息可靠传递
  * 目前常见的消息队列中间件产品包括：ActiveMQ 、ZeroMQ,RabbitMQ和Kafka
  * 一般消息中间件支持两种模式：消息队列模式及PubSub模式。

* Kafka：分布式发布-订阅消息系统（Pub-Sub模式），最初由LinkedIn公司开发，之后成为Apache项目的一部分。具有极高的消息吞吐量，较强的可扩展性和高可用性，消息传递低延迟，能够对消息队列进行持久化保存，且支持消息传递的"至少送达一次" 语义

* Kafka架构

<img width="763" alt="3501bd7e947da5e8e35c18cff929959" src="https://github.com/user-attachments/assets/cf5d63bc-408d-4277-8412-732ca7d1d9c7">

* 基本概念——Topics & Partition
  * Topics是消息的分类名（或Feed的名称），一个Topic可以认为是一类消息，每个topic将被分成多个partition(区)。partition是以log文件的形式存储在文件系统中，任何发布到partition的消息都会被直接追加到log文件的尾部。Logs文件根据配置要求,保留一定时间后删除来释放磁盘空间。
  * Partition： Topic物理上的分组，一 个 topic可以分为多个partition，每个 partition是一个有序的队列。partition中的每条消息都会被分配一个有序的 id（offset）。
  * Partition设计目的：
    * 通过分区,可以将日志内容分散到多个server上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存
    * 可以将一个topic切分多任意多个partitions,来提升消息保存/消费的效率
    * 越多的partitions意味着可以容纳更多的consumer，有效提升并发消费的能力

  
<img width="449" alt="9f8f7dae245ec35f989063b274a5a8e" src="https://github.com/user-attachments/assets/511b9e26-3ac7-48a2-afa8-56942905edaa">


* 基本概念——Producer
  * Producer 将消息发布到指定的Topic中,同时Producer 也能决定将此消息归属于哪个partition;比如基于"round-robin"方式或者通过其他的一些算法等
  * 消息和数据生产者，向 Kafka的一个topic发布消息的过程叫做 producers
  * 异步发送：批量发送可以很有效的提高发送效率。Kafka producer的异步发送模式允许进行批量发送，先将消息缓存在内存中，然后一次请求批量发送出去。

* 基本概念——Consumer
  * 消息和数据的消费者，订阅相关topics，并处理Producer发布的消息
  * 允许consumer group（包含多个consumer）对一个topic进行消费，不同的consumer group之间独立订阅
  * 每个consumer属于一个consumer group；发布的消息,只会被订阅此Topic的每个group中的一个consumer消费
  * 同一个group中不能有多于partitions个数的consumer同时消费,否则将意味着某些consumer将无法得到消息。
 
* 基本概念——Broker
  * Broker：缓存代理，Kafka 集群中的一台或多台服务器统称为 broker
  * 为了减少磁盘写入的次数，broker会将消息暂时buffer起来，当消息的个数(或尺寸)达到一定阀值时，再flush到磁盘，这样减少了磁盘IO调用的次数。
  * Broker不保存订阅者的状态，由订阅者自己保存。Broker没有副本机制，一旦broker宕机，该broker的消息将都不可用

* 基本概念——Message
  * Message消息：是通信的基本单位，每个 producer 可以向一个 topic（主题）发布一些消息
  * Kafka中的Message是以topic为基本单位组织的，不同的topic之间是相互独立的。每个topic又可以分成几个不同的partition(每个topic有几个partition是在创建topic时指定的)，每个partition存储一部分Message
  * partition中的每条Message包含了以下三个属性：
    * offset 对应类型：long
    * MessageSize 对应类型：int32
    * data 是message的具体内容

* Kafka的消息发送的流程

<img width="740" alt="280db882d7df1fd5e8ead7a9bf8808f" src="https://github.com/user-attachments/assets/334519ac-f52c-4e15-9e0b-ef52fcd486b2">

* Kafka的消息流示例

<img width="758" alt="9560364fa3ff29d126d7fb3673e6f3b" src="https://github.com/user-attachments/assets/1687b62a-26d9-4a96-990b-ce8a41e00e96">

* Kafka通过消息副本机制提供了高可用的消息服务， 其副本管理单位不是Topic消息队列，而是Topic的数据分片(Partition) 。在配置文件里可以指定数据分片的副本个数
* 在多个副本里，其中一个作为主副本(Leader)，其他作为次级副本(Slave) 。所有针对这个数据分片的消息读/写请求都由主副本来负责响应，次级副本只是以主副本数据消费者的方式从主副本同步数据

* Kafka是一个基于文件系统的消息系统，那么基于磁盘读写操作的消息系统如何保证系统性能？由于磁盘读/写因为涉及寻道操作这种机械运动，所以和内存读/写相比其效率极低。为此，考虑如何运用磁盘本身的特性来极大提升系统效率？
  * 原则：尽可能避免随机读/写，同时尽可能利用顺序读/写， 即连续读/写整块数据,Kafka能够高效处理大批量消息的一个重要原因就是将读/写操作尽可能转换为顺序读/写

## 其他数据采集
* 探针：网络流量数据捕获
* 传感器：环境数据捕获
* RFID Reader：标签数据捕获

